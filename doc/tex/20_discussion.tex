\section{Concluding Remarks}

\textbf{contribution:} The power of random variation and non-random selection
    to produce fine-tuned `hardware' has been extensively documented at various biomechanical levels. Classic examples include
    allometric scaling and anatomical adaptations (organism), width and material of blood vessels (organ), % \cite{holzapfel_biomechanics_2014},%valiant_evolvability_2009
    compartmentalization of sub-cellular components (cellular) and fast-folding and aggressively-functioning enzymes (molecular).
    Recent reports \cite{livnat_analytical_2011, chastain_algorithms_2014} have highlighted evidence for `software' optimization in biological systems from a computational complexity perspective, proposing justification for the evolutionary advantage for the role of sex for example \cite{livnat_sex_2016}.
    %
    Such investigations into evolutionary biology through the lens of computational complexity have hitherto been too high-abstracted. Nonetheless, they do demonstrate that computational-complexity perspective has potential to be the much-needed theoretical framework that can guide the process of turning massive volumes of biological datasets into actionable knowledge \cite{brenner_turing_2012}.

    There is currently  a gap between the ever increasing scale and quality of molecular interaction networks (MINs) and the oretical understanding of the origin of their architectural properties. It has long been debated whether properties such as the majority-leaves minority-hubs (mLmH) is (non-)adaptive. Here we showed how computational intractability can provide sufficient and necessary conditions for the emergence of mLmH as an adaptation to circumvent computational intractability. The model predicts and evolves the mLmH based on the fact as a gene's degree increases linearly, its optimization "ambiguity" potential increases exponentially and hence the more computationally expensive is the task of adaptively re-wiring the network away from a deleterious and into an advantageous state. We conjectured based on predictability results that there is ultimately  a universal edge:node ratio of ${\sim}$2 in all MINs. Given the increasing pace at which the coverage \cite{gerstein_architecture_2012,rolland_proteome-scale_2014} and resolution \cite{han_trrust:_2015,yang_widespread_2016} of high-throughput interaction-detecting experimental procedures is being reported, we expect the validity of such conjecture to be tested within a few years.

\textbf{sufficiency and necessity:} We described the need for biological networks to change their node (gene) and edge (interaction) composition in response to some evolutionary pressure as a computational optimization problem which we showed to be \myC{NP}-hard. By itself, the \myC{NP}-hardness of a problem is a rather weak measure of  computational difficulty.  Instances dealt with in practice may possess exploitable properties and as such their  optimal solutions could potentially be routinely found without incurring exponential computational resource expenditure \cite{vazirani_approximation_2013}. There could also exist good approximation algorithms that can solve to various degrees of optimality while consuming sub-exponential computational resources \cite{lawler_fast_1979}. However, in the context of biological evolution, the running algorithm is random-variation and non-random selection (RVnRS) and the instance difficulty of the network re-wiring problem must be assessed relative to it. Our results show that the search space size for the described network re-wiring problem would be exponentially orders of magnitude larger were the topology of biological networks to deviate significantly from mLmH.

    While the model sufficiently predicts and generates the mLmH topology, it also provides a necessary condition for the emergence of mLmH as an adaptation around inescapable computational intractability considering that (1) the computational cost of the network rewiring problem is, in the general case, universally insurmountable (assuming \myC{P}$\neq$\myC{NP}) and (2) RVnRS does not endow the organism with any heuristic-based approximation shortcuts that offer better than brute-force exploration of the search space.
    A sparse MIN where a gene has at most one interacting partner produces the easiest possible instances of the network-rewiring problem: regardless of the nature of the current evolutionary pressure, any gene can either be beneficial or damaging depending on whether the interaction it is engaged in is beneficial or damaging to the network as a whole. There is therefore no ambiguity as to which genes to conserve and which to delete/mutate in such a fully sparse network. However, such networks would necessarily contain more genes, since  functions that could have otherwise been accomplished by a single hub gene (e.g. a phosphatase targeting multiple proteins) must now be handled by a large number of specialty genes. This clearly leads to an explosion of genome size. On the other extreme, a dense network where functions are concentrated in as few  multi-tasking hub genes as possible would lead to an exponential search space. Particularly, the number of iterations of random-variation non-random selection needed before the network has been re-wired  away from a deleterious and into an advantageous state would be exponential in the number of unambiguous genes given some evolutionary pressure. That all genes in such a network are engaged in more than one interaction exponentially decreases their likelihood of being unambiguously advantageous or disadvantageous for the organism under a given evolutionary pressure scenario. An exponential number of iterations of random-variation and non-random selections are needed before the right set of genes have been conserved, deleted or mutated such that the total number of damaging interactions network-wide is under a tolerable threshold.

    mLmH topology is the middle ground between the two aforementioned extremes (the totally sparse but large, and the highly dense but unadaptable networks): essential functions are concentrated \cite{gerstein_architecture_2012} in `hub' genes that are unlikely to be damaging in and of themselves \cite{khurana_interpretation_2013}  while continuous (and cheap) experimentation (e.g. fine-tuning micro-RNA regulation \cite{gerstein_architecture_2012}) is conducted at the periphery of the network \cite{kim_positive_2007} with loosely connected leaf genes.

\textbf{applications and extensions:} An immediate application of the model is to complement statistical tests used to infer the quality and coverage of large-scale interactome-mapping wet experiments \cite{rolland_proteome-scale_2014} or \textit{in-silico} network inference \cite{mitra_integrative_2013}, by testing whether the resulting networks over- or under-represents real interactions relative to the prediction. There are aspects of the model that should be extended. In this work we treated all interactions as equal, but in reality some interactions are more potent than others. Future work could extend the model by considering the potency of each interaction, a not so trivial task since no large-scale data exist yet to facilitate its inference. The model is also static, in  that assigning benefit/damage to a gene is based on immediate neighbours only. The implication is that all genes are equal, but in reality a central gene (many shortest paths pass through it) has much more effect network-wide than a gene residing at the periphery of the network. Trivially, implementing a dynamic variant (where the cascading effect of a gene's beneficial (damaging) effects are accounted for) does not change the complexity class of NEP, although its simulations will be more computationally demanding.


  \begin{comment}
  \section{limitations:}

  level of abstraction

  doesn't detect small perturbations (as no. of neutral genes increases, the topology becomes irrelevant)

  gene invention (assume it's part of mutation)

  networks may be undirected / unsigned .. randomize. However, doesn't affect central point

  not all data are of equal quality

  benefit/damages only one edge away

  \end{comment}
